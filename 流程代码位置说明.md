# MinerU + RAGFlow å¤„ç†æµç¨‹ä»£ç ä½ç½®è¯´æ˜

## ğŸ“‹ æµç¨‹æ¦‚è§ˆ

æ ¹æ® UML å›¾ï¼Œæ•´ä¸ªæµç¨‹åˆ†ä¸ºä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼Œä»¥ä¸‹æ˜¯æ¯ä¸ªé˜¶æ®µå¯¹åº”çš„ä»£ç ä½ç½®ï¼š

---

## 1ï¸âƒ£ PDF ä¸Šä¼ é˜¶æ®µ

### ä»£ç ä½ç½®
- **æ–‡ä»¶**: `api/db/services/file_service.py`
- **å‡½æ•°**: `upload_document()` (çº¦ç¬¬ 200-300 è¡Œ)
- **è¯´æ˜**: å¤„ç†æ–‡ä»¶ä¸Šä¼ ï¼Œä¿å­˜åˆ°å­˜å‚¨ç³»ç»Ÿ

### ç›¸å…³ä»£ç 
```python
# api/db/services/file_service.py
@staticmethod
def upload_document(kb, file_objs, user_id):
    # ä¸Šä¼ æ–‡ä»¶åˆ°å­˜å‚¨
    # è¿”å›æ–‡ä»¶ä¿¡æ¯å’ŒäºŒè¿›åˆ¶æ•°æ®
```

---

## 2ï¸âƒ£ è§£æé˜¶æ®µå…¥å£

### ä»£ç ä½ç½®
- **æ–‡ä»¶**: `rag/svr/task_executor.py`
- **å‡½æ•°**: `run_dataflow()` (ç¬¬ 480-500 è¡Œ)
- **è¯´æ˜**: ä»»åŠ¡æ‰§è¡Œå™¨ï¼Œå¯åŠ¨ Pipeline å¤„ç†æµç¨‹

### å…³é”®ä»£ç 
```python
# rag/svr/task_executor.py:480
async def run_dataflow(task: dict):
    pipeline = Pipeline(dsl, tenant_id=..., doc_id=..., task_id=..., flow_id=...)
    chunks = await pipeline.run(file=task["file"])
```

### Pipeline æ‰§è¡Œ
- **æ–‡ä»¶**: `rag/flow/pipeline.py`
- **å‡½æ•°**: `Pipeline.run()`
- **è¯´æ˜**: Pipeline æ‰§è¡Œå¼•æ“ï¼ŒæŒ‰ DSL é…ç½®æ‰§è¡Œå„ä¸ªç»„ä»¶

---

## 3ï¸âƒ£ Parser ç»„ä»¶ - PDF è§£æ

### ä»£ç ä½ç½®
- **æ–‡ä»¶**: `rag/flow/parser/parser.py`
- **ç±»**: `Parser`
- **å‡½æ•°**: `_pdf()` (ç¬¬ 232-365 è¡Œ)

### å…³é”®æ­¥éª¤

#### 3.1 æ£€æŸ¥è§£ææ–¹æ³•
```python
# rag/flow/parser/parser.py:242
elif conf.get("parse_method").lower() == "mineru":
```

#### 3.2 åˆ›å»º MinerUParser
```python
# rag/flow/parser/parser.py:243-245
mineru_executable = os.environ.get("MINERU_EXECUTABLE", "mineru")
mineru_api = os.environ.get("MINERU_APISERVER", "http://host.docker.internal:9987")
pdf_parser = MinerUParser(mineru_path=mineru_executable, mineru_api=mineru_api)
```

#### 3.3 æ£€æŸ¥å®‰è£…
```python
# rag/flow/parser/parser.py:246-248
ok, reason = pdf_parser.check_installation()
if not ok:
    raise RuntimeError(...)
```

---

## 4ï¸âƒ£ MinerU å¤„ç†é˜¶æ®µ

### ä»£ç ä½ç½®
- **æ–‡ä»¶**: `deepdoc/parser/mineru_parser.py`
- **ç±»**: `MinerUParser`
- **å‡½æ•°**: `parse_pdf()` (ç¬¬ 534-609 è¡Œ)

### å…³é”®æ­¥éª¤

#### 4.1 å‡†å¤‡ä¸´æ—¶ç›®å½•å’Œæ–‡ä»¶
```python
# deepdoc/parser/mineru_parser.py:558-583
if binary:
    temp_dir = Path(tempfile.mkdtemp(prefix="mineru_bin_pdf_"))
    temp_pdf = temp_dir / pdf_file_name
    with open(temp_pdf, "wb") as f:
        f.write(binary)
```

#### 4.2 æå–å›¾ç‰‡
```python
# deepdoc/parser/mineru_parser.py:588
self.__images__(pdf, zoomin=1)
```

#### 4.3 è¿è¡Œ MinerU å¤„ç†
```python
# deepdoc/parser/mineru_parser.py:591
self._run_mineru(pdf, out_dir, method=method, backend=backend, lang=lang, server_url=server_url, callback=callback)
```
- **å‡½æ•°**: `_run_mineru()` (çº¦ç¬¬ 200-400 è¡Œ)
- **è¯´æ˜**: è°ƒç”¨ MinerU Server API æˆ–å‘½ä»¤è¡Œå·¥å…·å¤„ç† PDF

#### 4.4 è¯»å–å¤„ç†ç»“æœ
```python
# deepdoc/parser/mineru_parser.py:592
outputs = self._read_output(out_dir, pdf.stem, method=method, backend=backend)
```
- **å‡½æ•°**: `_read_output()` (ç¬¬ 461-500 è¡Œ)
- **è¯´æ˜**: è¯»å– MinerU è¾“å‡ºçš„ JSON æ–‡ä»¶

#### 4.5 è½¬æ¢ä¸º sections
```python
# deepdoc/parser/mineru_parser.py:597
return self._transfer_to_sections(outputs, parse_method), self._transfer_to_tables(outputs)
```
- **å‡½æ•°**: `_transfer_to_sections()` (ç¬¬ 502-529 è¡Œ)
- **è¯´æ˜**: å°† MinerU è¾“å‡ºè½¬æ¢ä¸º (text, positions) æ ¼å¼

---

## 5ï¸âƒ£ RAGFlow å¤„ç†é˜¶æ®µ

### ä»£ç ä½ç½®
- **æ–‡ä»¶**: `rag/flow/parser/parser.py`
- **å‡½æ•°**: `_pdf()` (ç¬¬ 257-335 è¡Œ)

### å…³é”®æ­¥éª¤

#### 5.1 ç”Ÿæˆ bboxes
```python
# rag/flow/parser/parser.py:257-264
bboxes = []
for t, poss in lines:
    box = {
        "image": pdf_parser.crop(poss, 1),
        "positions": [[pos[0][-1], *pos[1:]] for pos in pdf_parser.extract_positions(poss)],
        "text": t,
    }
    bboxes.append(box)
```

#### 5.2 åˆ†ç±»å¤„ç† (doc_type_kwd)
```python
# rag/flow/parser/parser.py:323-330
for b in bboxes:
    text_val = b.get("text", "")
    has_text = isinstance(text_val, str) and text_val.strip()
    layout = b.get("layout_type")
    if layout == "figure" or (b.get("image") and not has_text):
        b["doc_type_kwd"] = "image"
        # â¬‡ï¸ ä»»åŠ¡ 1.1 & 1.2: åœ¨è¿™é‡Œæ·»åŠ å›¾ç‰‡è¯†åˆ«å’Œå…ƒæ•°æ®å†™å…¥
    elif layout == "table":
        b["doc_type_kwd"] = "table"
```

#### 5.3 ä»»åŠ¡ 1.1 & 1.2: å›¾ç‰‡è¯†åˆ«å’Œå…ƒæ•°æ®å†™å…¥
**éœ€è¦æ·»åŠ ä»£ç çš„ä½ç½®**: `rag/flow/parser/parser.py` ç¬¬ 328 è¡Œä¹‹å

```python
# éœ€è¦æ·»åŠ çš„ä»£ç ç¤ºä¾‹ï¼ˆå‚è€ƒ rag/app/picture.py:76-86ï¼‰
if layout == "figure" or (b.get("image") and not has_text):
    b["doc_type_kwd"] = "image"
    
    # ä»»åŠ¡ 1.1: è°ƒç”¨å¤§æ¨¡å‹è¯†åˆ«å›¾ç‰‡
    try:
        cv_mdl = LLMBundle(self._canvas._tenant_id, LLMType.IMAGE2TEXT, lang=conf.get("lang"))
        img_binary = io.BytesIO()
        b["image"].save(img_binary, format="JPEG")
        img_binary.seek(0)
        image_description = cv_mdl.describe(img_binary.read())
        
        # ä»»åŠ¡ 1.2: å†™å…¥å…ƒæ•°æ®
        b["image_metadata"] = image_description
    except Exception as e:
        logging.warning(f"Failed to recognize image: {e}")
```

#### 5.4 æ·»åŠ ä¸Šä¸‹æ–‡
```python
# rag/flow/parser/parser.py:332-335
table_ctx = conf.get("table_context_size", 0) or 0
image_ctx = conf.get("image_context_size", 0) or 0
if table_ctx or image_ctx:
    bboxes = attach_media_context(bboxes, table_ctx, image_ctx)
```

#### 5.5 è¾“å‡ºç»“æœ
```python
# rag/flow/parser/parser.py:337-365
if conf.get("output_format") == "json":
    self.set_output("json", bboxes)
if conf.get("output_format") == "markdown":
    # è½¬æ¢ä¸º markdown æ ¼å¼
```

---

## 6ï¸âƒ£ Tokenizer å‘é‡åŒ–é˜¶æ®µ

### ä»£ç ä½ç½®
- **æ–‡ä»¶**: `rag/flow/tokenizer/tokenizer.py`
- **ç±»**: `Tokenizer`
- **å‡½æ•°**: `_invoke()` (ç¬¬ 128-203 è¡Œ)

### å…³é”®æ­¥éª¤

#### 6.1 æ¥æ”¶ chunks
```python
# rag/flow/tokenizer/tokenizer.py:128-133
async def _invoke(self, **kwargs):
    from_upstream = TokenizerFromUpstream.model_validate(kwargs)
    # chunks æ¥è‡ªä¸Šæ¸¸ Parser ç»„ä»¶
```

#### 6.2 å‘é‡åŒ–å¤„ç†
```python
# rag/flow/tokenizer/tokenizer.py:169-176
if "embedding" in self._param.search_method:
    chunks, token_count = await self._embedding(from_upstream.name, chunks)
```

#### 6.3 ä»»åŠ¡ 1.3: å…ƒæ•°æ®å‘é‡åŒ–
**ä»£ç ä½ç½®**: `rag/flow/tokenizer/tokenizer.py` ç¬¬ 64-95 è¡Œ

```python
# rag/flow/tokenizer/tokenizer.py:64-95
texts = []
for c in chunks:
    txt = ""
    # æå–åŸå§‹æ–‡æœ¬å­—æ®µ
    for f in self._param.fields:
        # ... æå– text å­—æ®µ ...
    
    # ä»»åŠ¡ 1.3: å…ƒæ•°æ®å‘é‡åŒ–
    if c.get("image_metadata"):
        image_metadata = c.get("image_metadata")
        if isinstance(image_metadata, str):
            txt += "\n" + image_metadata
        # ... å¤„ç†å…¶ä»–æ ¼å¼ ...
    
    # æ£€æŸ¥ metadata å­—æ®µ
    metadata = c.get("metadata")
    if isinstance(metadata, dict):
        if metadata.get("image_description"):
            txt += "\n" + str(metadata.get("image_description"))
    
    texts.append(txt)
```

#### 6.4 æ‰¹é‡ç¼–ç 
```python
# rag/flow/tokenizer/tokenizer.py:79-116
@timeout(60)
def batch_encode(txts):
    return embedding_model.encode([truncate(c, embedding_model.max_length - 10) for c in txts])

cnts_ = np.array([])
for i in range(0, len(texts), settings.EMBEDDING_BATCH_SIZE):
    vts, c = await trio.to_thread.run_sync(lambda: batch_encode(texts[i : i + settings.EMBEDDING_BATCH_SIZE]))
    # ... åˆå¹¶å‘é‡ ...
```

#### 6.5 å­˜å‚¨å‘é‡
```python
# rag/flow/tokenizer/tokenizer.py:122-125
for i, ck in enumerate(chunks):
    v = vects[i].tolist()
    ck["q_%d_vec" % len(v)] = v  # å­˜å‚¨å‘é‡åˆ° chunk
```

---

## 7ï¸âƒ£ å­˜å‚¨åˆ°çŸ¥è¯†åº“

### ä»£ç ä½ç½®
- **æ–‡ä»¶**: `rag/svr/task_executor.py`
- **å‡½æ•°**: `run_dataflow()` (ç¬¬ 520-777 è¡Œ)

### å…³é”®æ­¥éª¤

#### 7.1 æ£€æŸ¥æ˜¯å¦éœ€è¦å‘é‡åŒ–
```python
# rag/svr/task_executor.py:520-554
keys = [k for o in chunks for k in list(o.keys())]
if not any([re.match(r"q_[0-9]+_vec", k) for k in keys]):
    # å¦‚æœæ²¡æœ‰å‘é‡ï¼Œè¿›è¡Œå‘é‡åŒ–
    embedding_model = LLMBundle(...)
    # ... å‘é‡åŒ–å¤„ç† ...
```

#### 7.2 ä¿å­˜åˆ°å‘é‡æ•°æ®åº“
```python
# rag/svr/task_executor.py:600-777
# ä½¿ç”¨ search.index() ä¿å­˜ chunks åˆ°å‘é‡æ•°æ®åº“
# æ–‡ä»¶: rag/utils/ob_conn.py æˆ– rag/utils/opensearch_conn.py
```

---

## ğŸ“ å…³é”®æ–‡ä»¶æ¸…å•

### æ ¸å¿ƒå¤„ç†æ–‡ä»¶
1. **`rag/flow/parser/parser.py`** - Parser ç»„ä»¶ï¼ŒPDF è§£æå’Œåˆ†ç±»
2. **`deepdoc/parser/mineru_parser.py`** - MinerU è§£æå™¨å°è£…
3. **`rag/flow/tokenizer/tokenizer.py`** - Tokenizer ç»„ä»¶ï¼Œå‘é‡åŒ–å¤„ç†
4. **`rag/svr/task_executor.py`** - ä»»åŠ¡æ‰§è¡Œå™¨ï¼Œæµç¨‹åè°ƒ

### æ”¯æŒæ–‡ä»¶
5. **`rag/flow/pipeline.py`** - Pipeline æ‰§è¡Œå¼•æ“
6. **`rag/llm/embedding_model.py`** - Embedding æ¨¡å‹å®ç°
7. **`api/db/services/file_service.py`** - æ–‡ä»¶æœåŠ¡
8. **`rag/utils/ob_conn.py`** - å‘é‡æ•°æ®åº“è¿æ¥ï¼ˆOpenSearch/Infinityï¼‰

### å‚è€ƒæ–‡ä»¶
9. **`rag/app/picture.py`** - å›¾ç‰‡å¤„ç†å‚è€ƒå®ç°ï¼ˆç¬¬ 76-86 è¡Œï¼‰

---

## ğŸ” ä»»åŠ¡å®ç°ä½ç½®æ€»ç»“

| ä»»åŠ¡ | æ–‡ä»¶ | è¡Œå· | è¯´æ˜ |
|------|------|------|------|
| 1.1 å›¾ç‰‡è¯†åˆ« | `rag/flow/parser/parser.py` | 328 è¡Œä¹‹å | éœ€è¦æ·»åŠ  VLM è°ƒç”¨ |
| 1.2 å…ƒæ•°æ®å†™å…¥ | `rag/flow/parser/parser.py` | 328 è¡Œä¹‹å | éœ€è¦æ·»åŠ å…ƒæ•°æ®å­—æ®µ |
| 1.3 å…ƒæ•°æ®å‘é‡åŒ– | `rag/flow/tokenizer/tokenizer.py` | 74-95 è¡Œ | âœ… å·²å®ç° |

---

## ğŸ“ æ³¨æ„äº‹é¡¹

1. **MinerU Server**: éœ€è¦å•ç‹¬è¿è¡Œï¼Œé€šè¿‡ API æˆ–å‘½ä»¤è¡Œè°ƒç”¨
2. **VLM Model**: ä½¿ç”¨ `LLMBundle(tenant_id, LLMType.IMAGE2TEXT, lang=...)`
3. **å‘é‡åŒ–**: åœ¨ Tokenizer ç»„ä»¶ä¸­è‡ªåŠ¨å¤„ç†ï¼Œå·²æ”¯æŒå…ƒæ•°æ®å‘é‡åŒ–
4. **å­˜å‚¨**: å‘é‡å’Œå…ƒæ•°æ®ä¼šè‡ªåŠ¨ä¿å­˜åˆ°çŸ¥è¯†åº“

